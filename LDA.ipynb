{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introdução "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ***Linear Discriminant Analsysis (LDA)*** é uma técnica muito utilizada para redução de dimensionalidade na etapa de pré-processamento em aplicações de reconhecimento de padrões e aprendizagem de máquina. **O objetivo é projetar o dataset em um espaço de menor dimensões com uma boa separação das classes para evitar overfitting e reduzir o custo computacional**.\n",
    "\n",
    "A abordagem do LDA é bem semelhante a do PCA, no entanto, **além de encontrar os componentes que maximizam a variância dos nossos dados (PCA), nós também estamos interessados nos componentes que maximizam a separação entre múltiplas classes (LDA)**.\n",
    "\n",
    "Resumindo, o objetivo do LDA é projetar um espaço de atributos (um banco de dados com amostras n-dimensional) em um subespaço menor ***k*** (onde $k \\leq n-1$) mantendo a informação de discriminação das classes.\n",
    "\n",
    "Em geral, a redução de dimensionalidade ajuda não somente a reduzir custos computacionais para um dado problema de classificação, mas também é útil para evitar o overfitting pela minimização do erro na estimação de parâmetros.\n",
    "\n",
    "## PCA vs LDA\n",
    "\n",
    "Ambos PCA e LDA são técnicas de transformações lineares bastante utilizadas para redução de dimensionalidade. Por um lado, o PCA pode ser descrito como um algoritmo \"não-supervisionado\", já que ele \"ignora\" os rótulos das classes e seu objetivo é encontrar as direções (componentes principais) que maximizam a variância no banco de dados. Por outro lado, o LDA é \"supervisionado\" e calcula as direções (discriminantes lineares) que vão representar os eixos que maximizam a separação entre múltiplas classes.\n",
    "\n",
    "Embora pareça que o LDA seja superior ao PCA em problemas de multi-classificação onde os rótulos das classes são conhecidos, nem sempre isso acontece. Por exemplo, comparações entre acurácias de classificação para reconhecimento de imagens após o uso de PCA ou LDA mostra que **o PCA tende a ser melhor que o LDA se o número de amostras/classe é relativamente pequeno** (<a href=\"http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=908974\">PCA vs LDA</a>, A.M. Martinez et al., 2001). Na prática, também é comum usar ambos LDA e PCA em conjunto, isto é, PCA para redução de dimensionalidade seguido por um LDA.\n",
    "\n",
    "<img src=\"images/PCAvsLDA.png\" width=600>\n",
    "\n",
    "### O que é um \"bom\" subespaço?\n",
    "\n",
    "Supondo que nosso objetivo é reduzir as dimensões de um dataset ***d***-dimensional pela projeção em um subespaço ***k***-dimensional (onde ***k < d***). Então, como saber qual tamanho devemos escolher para ***k*** (***k*** = o número de dimensões do novo subespaço de atributos), e como saber se nós temos um espaço de atributos que representa \"bem\" nossos dados?\n",
    "\n",
    "Em breve, nós vamos calcular os autovetores (componentes) do nosso dataset e coletá-los em matrizes chamadas *matrizes-esparsas (scatter-matrizes)*, ou melhor, matrizes esparsas intra-classes e inter-classes. Cada um desses autovetores é associado a um autovalor que nos diz o \"tamanho\" ou \"magnitude\" dos autovetores.\n",
    "\n",
    "**Se observamos que todos autovalores tem uma magnitude similar, então isso pode ser um bom indicador que nossos dados já estão projetados em um \"bom\" espaço de atributos.**\n",
    "\n",
    "Por outro lado, se alguns autovalores tem a magnitude muito maior que a dos outros, devemos escolher seus autovetores já que eles contém mais informação sobre a distribuição dos nossos dados. Da mesma forma, autovalores próximos a zero são menos informativos e devemos desconsiderá-los na construção do nosso subespaço.\n",
    "\n",
    "## Aplicação\n",
    "\n",
    "Em geral, a aplicação do LDA envolve a aplicação dos seguintes passos:\n",
    "1. Calcular a média (vetor **d**-dimensional) para cada uma das classes do dataset\n",
    "2. Calcular as scatter-matrices (intra-classe e inter-classe)\n",
    "3. Calcular os autovetores ($e_1, e_2, ..., e_d$) e seus correspondentes autovalores ($\\lambda_1, \\lambda_2,...\\lambda_d$) para as scatter-matrices.\n",
    "4. Ordenar os autovetores pelos autovalores em ordem decrescente e escolher os ***k*** autovetores com os maiores autovalores para formar uma matriz **W** [$d \\times k$], onde cada coluna representa um autovetor.\n",
    "5. Usar **W** para transformar as amostras no novo subespaço. Isso pode ser resumido pela multiplicação de matrizes: $Y = X \\times W$ (onde **X** [$n \\times d$] é a matriz que representa nosso dataset com ***n*** amostras, e **Y** é matriz das amostras transformadas no novo subespaço [$n \\times k$]).\n",
    "\n",
    "## Suposições de Normalidade\n",
    "\n",
    "Assim como outros algoritmos, o LDA assume que os dados são normalmente distribuidos, os atributos são estatisticamente independentes e matriz de covariância idênticas para cada classe. Entretanto, isso só se aplica ao LDA como classificador. Como redutor de dimensionalidade, o LDA também funciona razoavelmente bem se essas suposições forem violadas. E mesmo para tarefas de classificação o LDA pode ser robusto a distribuição dos dados:\n",
    "\n",
    "> “linear discriminant analysis frequently achieves good performances in the tasks of face and object recognition, even though the assumptions of common covariance matrix among groups and normality are often violated (Duda, et al., 2001)” <a href=\"http://link.springer.com/article/10.1007%2Fs10115-006-0013-y\">(Tao Li, et al., 2006)</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse tutorial, vamos utilizar o **Iris dataset**, já presente no scikit-learn. O Iris dataset contém dados de 150 flores divididas em 3 espécies diferentes (setosa, versicolor, virginica). Os dados são:\n",
    "\n",
    "1. sepal lenght em cm\n",
    "2. sepal width em cm\n",
    "3. petal length em cm\n",
    "4. petal width em cm\n",
    "\n",
    "<img src=\"images/Iris-dataset.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     class  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['class'] = iris.target\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)       class  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "x = df.drop(labels='class', axis=1).values\n",
    "y = df['class'].values\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Implementação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA():\n",
    "    def __init__(self, n_components=None):\n",
    "        self.n_components = n_components\n",
    "        self.priors_ = None\n",
    "        self.means_ = []\n",
    "        self.covariance_ = []\n",
    "        self.overall_mean = 0.0\n",
    "        self.eigen_values = None\n",
    "        self.eigen_vectors = None\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        # Passo 1: calcular os vetores médios para cada classe\n",
    "        classes = np.unique(y)\n",
    "        n_classes = len(classes)\n",
    "        n_samples, n_features = x.shape\n",
    "        self.priors_ = np.bincount(y) / float(len(y))\n",
    "        self.max_components = n_classes - 1 if self.n_components is None else np.clip(self.n_components, 1, n_classes-1)\n",
    "        \n",
    "        self.means_ = np.array([np.mean(x[y == c], axis=0) for c in classes])\n",
    "        self.covariance_ = np.array([p * np.cov(x[y == c], rowvar=False, bias=1) for p, c in zip(self.priors_, classes)]).sum(axis=0)\n",
    "            \n",
    "        # Passo 2: Calcular as scatter matrices\n",
    "        self.overall_mean = np.mean(x, axis=0).reshape(1, n_features)\n",
    "        S_w = np.zeros(shape=(n_features, n_features))\n",
    "        S_b = np.zeros(shape=(n_features, n_features))\n",
    "        for p, c, mean_vec in zip(self.priors_, classes, self.means_):\n",
    "            class_samples = x[y == c]\n",
    "            S_w += (1 / n_samples) * np.dot((class_samples - mean_vec).T, (class_samples - mean_vec))\n",
    "            S_b += p * np.dot((mean_vec - self.overall_mean).T, mean_vec - self.overall_mean)\n",
    "            \n",
    "#         S_w = self.covariance_\n",
    "#         St = np.cov(x.T, bias=1)\n",
    "#         Sb2 = St - S_w\n",
    "\n",
    "        print(S_w, S_b, sep='\\n\\n', end='\\n\\n')\n",
    "            \n",
    "        # Passo 3: Calcular os autovalores e autovetores\n",
    "        self.eigen_values, self.eigen_vectors = np.linalg.eig(np.linalg.inv(S_w).dot(S_b.T))\n",
    "        self.eigen_vectors *= -1\n",
    "        \n",
    "        self.sorted_components_ = np.argsort(self.eigen_values)[::-1]\n",
    "        \n",
    "        self.projection_matrix_ = self.eigen_vectors[self.sorted_components_[:self.n_components]]\n",
    "\n",
    "        self.explained_variance_ = self.eigen_values[self.sorted_components_]\n",
    "        self.explained_variance_ratio_ = self.explained_variance_ / self.eigen_values.sum()\n",
    "        \n",
    "    \n",
    "    def predict(self, x):\n",
    "        pass\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return np.dot(x - self.overall_mean, self.projection_matrix_.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Teste "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.259708   0.09086667 0.164164   0.03763333]\n",
      " [0.09086667 0.11308    0.05413867 0.032056  ]\n",
      " [0.164164   0.05413867 0.181484   0.041812  ]\n",
      " [0.03763333 0.032056   0.041812   0.041044  ]]\n",
      "\n",
      "[[ 0.42141422 -0.13301778  1.101656    0.47519556]\n",
      " [-0.13301778  0.07563289 -0.38159733 -0.15288444]\n",
      " [ 1.101656   -0.38159733  2.91401867  1.24516   ]\n",
      " [ 0.47519556 -0.15288444  1.24516     0.53608889]]\n",
      "\n",
      "[ 3.21919292e+01  2.85391043e-01 -5.55955918e-15  5.94117204e-16]\n",
      "[[ 0.20874182  0.00653196  0.60506803 -0.30816065]\n",
      " [ 0.38620369  0.58661055  0.04664624  0.41692065]\n",
      " [-0.55401172 -0.25256154  0.11350006  0.47494459]\n",
      " [-0.7073504   0.76945309 -0.78666038 -0.71108497]]\n"
     ]
    }
   ],
   "source": [
    "lda = LDA()\n",
    "lda.fit(x, y)\n",
    "\n",
    "# print(lda.means_)\n",
    "# print(lda.covariance_)\n",
    "print(lda.eigen_values)\n",
    "print(lda.eigen_vectors)\n",
    "# print(lda.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação com o Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.259708   0.09086667 0.164164   0.03763333]\n",
      " [0.09086667 0.11308    0.05413867 0.032056  ]\n",
      " [0.164164   0.05413867 0.181484   0.041812  ]\n",
      " [0.03763333 0.032056   0.041812   0.041044  ]]\n",
      "\n",
      "[[ 0.42141422 -0.13301778  1.101656    0.47519556]\n",
      " [-0.13301778  0.07563289 -0.38159733 -0.15288444]\n",
      " [ 1.101656   -0.38159733  2.91401867  1.24516   ]\n",
      " [ 0.47519556 -0.15288444  1.24516     0.53608889]]\n",
      "\n",
      "[-3.23310228e-14 -4.19979353e-15  2.85391043e-01  3.21919292e+01]\n",
      "\n",
      "[[ 2.7405497  -1.68869897  0.02434685  0.83779794]\n",
      " [-2.690797   -0.31709557  2.18649663  1.55005187]\n",
      " [-2.99433611 -0.54273126 -0.94138258 -2.22355955]\n",
      " [ 3.75823777  2.66704003  2.86801283 -2.83899363]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[[ 0.20874182  0.00653196 -0.52465543  0.44550654]\n",
      " [ 0.38620369  0.58661055 -0.09851721 -0.43741869]\n",
      " [-0.55401172 -0.25256154 -0.1686191  -0.48676231]\n",
      " [-0.7073504   0.76945309  0.82861248  0.61094294]]\n"
     ]
    }
   ],
   "source": [
    "lda_sk = LinearDiscriminantAnalysis(n_components=None, solver='eigen', store_covariance=True)\n",
    "lda_sk.fit(x, y)\n",
    "\n",
    "# print(lda_sk.means_)\n",
    "# print(lda_sk.covariance_)\n",
    "print(lda_sk.scalings_)\n",
    "# print(lda_sk.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.49920971 1.88675441]\n",
      " [1.2643595  1.59214275]\n",
      " [1.35525305 1.73341462]\n",
      " [1.18495616 1.62358806]\n",
      " [1.5169559  1.94476227]]\n",
      "[0 0 0 0 1 1 1 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "x_proj_sk = lda_sk.transform(x)\n",
    "y_pred_sk = lda_sk.predict(x[::15])\n",
    "\n",
    "print(x_proj_sk[:5])\n",
    "print(y_pred_sk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Implementação Original do Scikit-learn](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/discriminant_analysis.py)\n",
    "- [Linear Discriminant Analysis](https://sebastianraschka.com/Articles/2014_python_lda.html)\n",
    "- [Linear discriminant analysis: A detailed tutorial](https://www.researchgate.net/publication/316994943_Linear_discriminant_analysis_A_detailed_tutorial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
